- [1. 개정이력](#1-%EA%B0%9C%EC%A0%95%EC%9D%B4%EB%A0%A5)
- [2. Audience](#2-audience)
- [3. 사전 준비](#3-%EC%82%AC%EC%A0%84-%EC%A4%80%EB%B9%84)
- [4. k8s 환경 web-application 서비스](#4-k8s-%ED%99%98%EA%B2%BD-web-application-%EC%84%9C%EB%B9%84%EC%8A%A4)
  - [4.1. Dockerfile 작성](#41-dockerfile-%EC%9E%91%EC%84%B1)
  - [4.2. ConfigMap](#42-configmap)
  - [4.3. Deployment](#43-deployment)
  - [4.4. Service](#44-service)
- [5. k8s 환경 batch-application 서비스](#5-k8s-%ED%99%98%EA%B2%BD-batch-application-%EC%84%9C%EB%B9%84%EC%8A%A4)
  - [5.1. Job](#51-job)
  - [5.2. CronJob](#52-cronjob)
- [6. k8s Pods간 통신 제어](#6-k8s-pods%EA%B0%84-%ED%86%B5%EC%8B%A0-%EC%A0%9C%EC%96%B4)
  - [6.1. NetworkPolicy](#61-networkpolicy)
  - [6.2. Namespace 간 통신 제약 정책 적용하기](#62-namespace-%EA%B0%84-%ED%86%B5%EC%8B%A0-%EC%A0%9C%EC%95%BD-%EC%A0%95%EC%B1%85-%EC%A0%81%EC%9A%A9%ED%95%98%EA%B8%B0)
- [7. k8s Pods의 Node 배치](#7-k8s-pods%EC%9D%98-node-%EB%B0%B0%EC%B9%98)
  - [7.1. nodeSelector](#71-nodeselector)
  - [7.2. nodeName](#72-nodename)

# 1. 개정이력

|    날짜    | 변경내용  | 작성자 | 비고 |
| :--------: | :-------: | :----: | :--: |
| 2019.03.08 | 최초 작성 | 전원호 |      |
|            |           |        |      |
|            |           |        |      |



# 2. Audience

- 컨테이터 클러스터 환경에서 웹 어플리이케션을 구현하는 자.
- 컨테이터 클러스터 환경에서 배치 어플리이케션을 구현하는 자.
- 컨테이터 클러스터 내 어플이케이션 간 서비스 통신을 구현하는 자.
- Pods 간 통신 제약 및 Node 배치를 제어하고자 하는 자. 



# 3. 사전 준비

- .vimrc

```bash
set smartindent
set tabstop=2
set expandtab
set shiftwidth=2
```

docker, kubernetes, istio환경에서 개발을 하다보면 yaml 파일 작성일 필수적이다. 이에 따라 vi 환경에서 tab 버튼을 통해 smartindent가 되도록 설정한다.



- alias 설정

```bash
alias i='istioctl -n millet'
alias k='kubectl -n millet'
alias ki='kubectl -n istio-system'
alias oc='oc -n millet'
alias oci='oc -n istio-system'
```

DEV cli 환경에서 테스트 시 좀 더 편한 설정 작업을 위해서 kubectl, oc, istioctl 명령에 대한 namespace 설정이 필요하다. 이에 위의 예제의 경우 "millet" namespace 정보를 alias 설정하여 사용하도록 한다.



# 4. k8s 환경 web-application 서비스

- application jar 파일 준비(Optional)

```bash
-rwxr--r--. 1 root root 26710798 Mar  4 14:54 Kmc-0.0.1-SNAPSHOT.jar
```

spring boot를 가지고 작성된 Kmc application을 가지고 설명하며 해당 application은 컨테이너 클러스터 밖의 VM DB와 대외기관 KMC(한국모바일인증)와 연동하는 구조를 가지고 있다.

실제 프로젝트에서는 git Repository에 해당 application의 소스가 관리되고 jenkins와 같은 build tool에 의해 소스가 build되어 정해진 target Directory jar와 같은 archive 파일이 생성된다.



## 4.1. Dockerfile 작성

Dockerfile

```bash
FROM ktis-bastion01.container.ipc.kt.com:5000/admin/openjdk-millet:8-jdk-alpine

LABEL owner=mmp-project-team
ENV TZ Asia/Seoul

# ahtn ssl client certificate import
RUN mkdir -p /java.io/keystores
COPY src/main/resources/cert/kmcert1.cer /java.io/keystores
RUN keytool -import -alias kmcTrust -file /java.io/keystores/kmcert1.cer -keystore /java.io/keystores/truststore.jks -storepass mmpProject -noprompt

COPY target/*.jar app.jar
ENV JAVA_OPTS="-Xms1G -Xmx1G -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=256m"
ENV JAVA_OPTS="${JAVA_OPTS} -XX:+UseG1GC -XX:+UnlockDiagnosticVMOptions -XX:+G1SummarizeConcMark -XX:InitiatingHeapOccupancyPercent=35 -XX:G1ConcRefinementThreads=20"

# ahtn ssl client certificate ENV
ENV JAVA_OPTS="${JAVA_OPTS} -Djavax.net.ssl.trustStore=/java.io/keystores/truststore.jks -Djavax.net.ssl.trustStorePassword=mmpProject"

ENTRYPOINT ["sh","-c","java $JAVA_OPTS -Djava.security.egd=file:/dev/./urandom -jar /app.jar"]

```

- 자세한 docker command 관련해서 http://gitlab.msa.kt.com/coe-istio-master/public-documents/tree/master/knowledge-asset/docker 를 참조하도록 한다.
- `ktis-bastion01.container.ipc.kt.com:5000/admin/openjdk-millet:8-jdk-alpine` 프로젝트의 base image로 해당 이미지는 apline linux에 openjdk 1.8버전을 근간으로 curl 명령어를 가지고 있다. (그외 nc, ping, wget, jmap, jstack 등)

- client에서 사용하는 서버측 인증서를 가지고 https 통신을 하기 위한 jks(Java Key Store) 설정 작업이 존재한다. 이는 `11. 보안 가이드라인 - 01. SSL 연동 가이드` 가이드 내용과 비교하여 선택적으로 활용할 수 있다.

- 이미지 생성

```bash
docker build --no-cache -t docker-registry.default.svc.cluster.local:5000/mmp/athn:latest -f Dockerfile .
```

docker build 작업은 jenkins에서 이루어진다.

- 이미지 클러스터 docker registry에 push

```bash
docker push docker-registry.default.svc.cluster.local:5000/mmp/athn:latest 
```

docker push작업은 jenkins에서 이루어진다.



## 4.2. ConfigMap

ConfigMap은 application에서 사용하는 설정 정보들에 대해 관리하는 object이다. 동일하게 Secret을 활용할 수 있으며 차이는 value에 대한 암호화 지원여부이다.

- 300-micro-svc-1-configmap.yaml 사용 예시

```yml
apiVersion: v1
kind: ConfigMap
metadata:
  name: micro-svc-1
  labels:
    app: micro-svc-1
    version: 1.0.0
    release: mmp
data:
  SVC1HOST: "service-micro-svc-1.herasoo.svc.cluster.local"
  SVC2HOST: "service-micro-svc-2.herasoo.svc.cluster.local"
  SVC1PORT: "80"
  SVC2PORT: "80"
  DB_HOST: "10.217.59.20"
  DB_PORT: "5432"
  DB_DBNAME: "postgres"
  DB_USER: "postgres"
  DB_PASSWD: "postgres" # passwd와 같은 민감정보는 암호화가 필요하다.
```

spring boot로 작성된 application에서 사용할 환경변수를 필요 시 환경별로 동적으로 관리하기 위함이다.

위의 정보는 spring boot application 내 application.yaml에 아래와 같이 정의 되어 있다.

```yaml
server:
  port: 8080
  servlet:
    context-path: /svc1

spring:
  datasource:
    url: jdbc:postgresql://${DB_HOST:localhost}:${DB_PORT:5432}/${DB_DBNAME:postgres}
    driver-class-name: org.postgresql.Driver
    username: ${DB_USER:postgres}
    password: ${DB_PASSWD:postgres}
    hikari:
      connection-test-query: select 1
      connection-timeout: 5000
      idle-timeout: 30000
  jpa:
    database-platform: org.hibernate.dialect.PostgreSQLDialect
    
herasoo:
  name: wonho
  host:
    svc1: ${SVC1HOST:localhost}
    svc2: ${SVC2HOST:localhost}
  port:
    svc1: ${SVC1PORT:8080}
    svc2: ${SVC2PORT:8090}
debug: false
```

Application 내부에서 는 다음과 같이 환경변수를 활용할 수 있다.

```java
@Value("${herasoo.port.svc2}")
private String svc2Port;
```



- 300-mmp-athn-configmap.yaml 사용 예시

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: athn
  labels:
    app: athn
    version: 1.0.0
    release: mmp
data:
  spring.profiles.active: "dev"
```

spring boot의 spring.profiles 기능을 활용하여 application.yaml에 환경별로 사용할 설정 정보를 관리할 수 있다. 이는 첫번째 ConfigMap 예시보다 효율적이고 직관적으로 관리할 수 있으며 민감정보에 대해 보다 쉽게 관리할 수 있다. 아래의 application.yaml은 dev, prd 공통으로 사용하는 부분과 각 dev, prd 환경에 적용되어야 하는 부분이 구분되어 표기되어 있다.

```yaml
# embeded tomcat
server:
  servlet:
    context-path: /athn
  tomcat:
    uri-encoding: UTF-8      
  error:
    whitelabel:
      enabled: true  
  compression:
    enabled: true
  port: 80
  
# log file name  
logging:
  file: kmc
  path: /var/log
  level:
    com:
      kt:
        athn:
          mapper: TRACE
          model: TRACE
          dao: TRACE

#jasypt encryptor
jasypt:
  encryptor:
    bean: jasyptStringEncrptor
      
# spring boot - actuator expose
management:
  endpoints:
    web:
      exposure:
        include: health, prometheus 
       
---

# Dev Profile
spring:
  profiles: dev
  datasource:
    url: jdbc:postgresql://10.217.59.68:5432/mmpdb
    username: mmpown
    password: ENC(uIqx+krC3maqJVC1L+MXXkcLeGoLMUPi5nH/BRQX75fdtx9L3emtlQ==)
    driver-class-name: org.postgresql.Driver
  http:
    encoding:
      charset: UTF-8
      enabled: true
      force: true
      
---

# Prd Profile
spring:
  profiles: prd
  datasource:
    url: jdbc:postgresql://10.220.184.171:5432/mmpdb
    username: mmpown
    password: ENC(uIqx+krC3maqJVC1L+MXXkcLeGoLMUPi5nH/BRQX75fdtx9L3emtlQ==)
    driver-class-name: org.postgresql.Driver
  http:
    encoding:
      charset: UTF-8
      enabled: true
      force: true
```



## 4.3. Deployment

deployment --> replicaset --> pod를 생성한다.

해당 object에 대한 자세한 내용은 https://kubenetes.io/docs/concepts/workloads/controllers/deployment/ 를 참고한다.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: athn
  labels:
    app: athn
    version: 1.0.0
    release: mmp
spec:
  selector:
    matchLabels:
      app: athn
      version: 1.0.0
      release: mmp
  replicas: 1
  template:
    metadata:
      labels:
        app: athn
        version: 1.0.0
        release: mmp
      #annotations:
        #sidecar.istio.io/inject: "true"
    spec:
      containers:
      - name: athn
        image: docker-registry.default.svc.cluster.local:5000/mmp/athn:latest
        #imagePullPolicy: IfNotPresent
        imagePullPolicy: Always
        ports:
        - containerPort: 80
        envFrom:
        - configMapRef:
            name: athn
        #args: ["java","-Djava.security.egd=file:/dev/./urandom","-Dspring.profiles.active=$(spring.profiles.active)","-jar","/app.jar"]
        volumeMounts:
        - mountPath: /var/log/LAMP/
          name: lamp-volume
        - mountPath: /etc/localtime
          name: timezone-config
        securityContext:
          privileged: true
        livenessProbe:
          httpGet:
            path: /athn/actuator/health
            port: 80
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /athn/actuator/health
            port: 80
          initialDelaySeconds: 30
          periodSeconds: 10
        resources:
          requests:
            memory: "1250Mi"
          limits:
            cpu: "2000m"
            memory: "1250Mi"
      nodeSelector:
        ktis-node: "true"
        #node-role.kubernetes.io/infra: "true"
      volumes:
      - name: lamp-volume
        hostPath:
          # directory location on host
          path: /var/log/mmp/LAMP/
          # this field is optional
          type: DirectoryOrCreate
      - hostPath:
          path: /usr/share/zoneinfo/Asia/Seoul
        name: timezone-config
```


- Pod template 내 명시하여 해당 pod에 istio-proxy를 injection 여부를 설정한다.

```yaml
    annotations:
      sidecar.istio.io/inject: "true"
```

- imagePullPolicy: Always (Always, IfNotPresent, Never. dafault는 IfNotPresent)

- livenessProbe: 컨테이너의 상태가 비정상이라고 판단하면, 해당 Pod를 재시작

  - http, tcp, sh 방식이 존재하고 spring boot의 경우 actuator 기능을 활용하여 위와 같이 http 방식을 활용한다.

  - tcp 방식 참조

  ```yaml
           livenessProbe:
             tcpSocket:
               port: 80
             initialDelaySeconds: 30
             periodSeconds: 10
  ```


- readinessProbe: 컨테이너가 상태가 비정상이라고 판단하면, 해당 Pod를 사용할 수 없음으로 표시하고, 서비스등에서 제외

  - http, tcp, sh 방식이 존재하고 spring boot의 경우 actuator 기능을 활용하여 위와 같이 http 방식을 활용한다.

  - tcp 방식 참조

  ```yaml
           readinessProbe:
             tcpSocket:
               port: 80
             initialDelaySeconds: 30
             periodSeconds: 10
  ```

- restartPolicy: Always (Always, OnFailure, and Never. default는 Always)

- Pod 내 resources 절을 통하여 cpu 및 memory 크기에 대한 기동 시와 max 제한 값을 설정할 수 있다. 요청 시 memory는 1.25G, 제한은 cpu 2 cores와 memory 1.25G로 제한한다. 

```yaml
         resources:
           requests:
             memory: "1250Mi"
           limits:
             cpu: "2000m"
             memory: "1250Mi"
```

-   Node의 TZ(Time Zone) 설정 파일을 Mount하여 TZ을 동기한다.

```yaml
         volumeMounts:
         - mountPath: /etc/localtime
           name: timezone-config
       volumes:
       - hostPath:
           path: /usr/share/zoneinfo/Asia/Seoul
         name: timezone-config
```


## 4.4. Service

컨테이너 클러스터 환경에서 Pod의 IP는 시작, 재시작 시 배치되는 Node의 위치에 따라 IP 정보는 변경된다. 그래서 Pod의 동적 부분을 정적으로 서비스하기 위해 Service 객체를 활용하는데 Pod 내부에서 컨테이너 클러스터 환경 내 다른 Pod로 호출 시 Service 객체를 활용하고 그 때 host 정보는 Service 객체의 name이 된다. 해당 host 정보는 kube-dns에 의해 관리된다.

동일 Namespace 안에서는 `service-micro-svc-1`와 같이 Service name으로 지칭하고 다른 Namespace의 Service의 경우FQDN 방식의 `service-micro-svc-1.herasoo.svc.cluster.local (서비스명.namespace명.svc.cluster.local)`와 같이 사용한다.

```yaml
apiVersion: v1
kind: Service
metadata:
  name: athn
  labels:
    app: athn
    version: 1.0.0
    release: mmp
spec:
  #type: NodePort
  type: ClusterIP
  ports:
  - name: http
    port: 80
    targetPort: 80
    #clusterIP: None
    selector:
    app: athn
```

Service는 지정된 selector `app: athn`에 의해 Pod를 호출하며 기본적으로 round robin 방식으로 동작한다. selector에 의해 pod가 선정된 경우 Service Name과 동일하게 Endpoints object가 생성되어 Endpoints 정보를 확인할 수 있다.



# 5. k8s 환경 batch-application 서비스



## 5.1. Job

job --> pod를 생성한다. 일회성 배치 작업 실행 시 활용된다.

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: setl
  labels:
     app: setl
     version: 1.0.0
     release: mmp
spec:
  #ttlSecondsAfterFinished: 50
  backoffLimit: 2
  #completions: 5
  #parallelism: 2
  template:
     metadata:
       name: batch
       labels:
         app: setl
         version: 1.0.0
         release: mmp
     spec:
       containers:
         - name: setl
           image: docker-registry.default.svc.cluster.local:5000/mmp/batch:latest
           envFrom:
           - configMapRef:
               name: setl
           #args: ["java","-Djava.security.egd=file:/dev/./urandom","-Dspring.profiles.active=$(spring.profiles.active)","-jar","/app.jar"]
           resources:
             requests:
               memory: "1250Mi"
             limits:
               cpu: "2000m"
               memory: "1250Mi"
           volumeMounts:
           - mountPath: /etc/localtime
             name: timezone-config
       restartPolicy: Never
       nodeSelector:
         ktis-node: "true"
       volumes:
       - hostPath:
           path: /usr/share/zoneinfo/Asia/Seoul
         name: timezone-config
```

- #ttlSecondsAfterFinished: 50, Pod가 종료되면 50s 후 지워진다. 0은 바로 지운다. v1.12 이후 제공
- backoffLimit: 2, 실패 시 재 시작 회수로 +1만큼의 Pod가 생성된다, default는 6
- #completions: 5, Completed Pods의 개수
- #parallelism: 2, 1이면 순차처리이고 동시 실행하는 Pods의 개수, default 1
- restartPolicy: Never, Never or OnFailure, Never는 새로운 Pod로 기동되고 OnFailure는 기존 Pod가 RESTART된다.

- Job이 실행되면 정의된 spec에 맞추어 Pods를 실행시키고 Completed, Error상태로 종료된다. 이는 Pod의 프로세스 exit코드(0이면 성공, 그외 실패)에 의해서 관리되는데 실패 시 설정에 따라 재 실행여부를 결정 할 수 있다.



## 5.2. CronJob

Cron job은 time-based schedule에 맞추어 Job을 생성한다. 주기성 배치 작업 실행 시 활용된다.

cron job --> job --> pod를 생성한다.

```yaml
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: setl
  labels:
    app: setl
    version: 1.0.0
    release: mmp
spec:
  #schedule: '@daily'
  schedule: "0 */1 * * *"
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 1
  jobTemplate:
    spec:
      #ttlSecondsAfterFinished: 50
      backoffLimit: 2
      #completions: 5
      #parallelism: 2  # default 1
      template:
        spec:
          containers:
            - name: setl
              image: docker-registry.default.svc.cluster.local:5000/mmp/batch:latest
              envFrom:
              - configMapRef:
                  name: setl
              #args: ["java","-Djava.security.egd=file:/dev/./urandom","-Dspring.profiles.active=$(spring.profiles.active)","-jar","/app.jar"]
              resources:
                requests:
                  memory: "1250Mi"
                limits:
                  cpu: "2000m"
                  memory: "1250Mi"
              volumeMounts:
              - mountPath: /etc/localtime
                name: timezone-config
          restartPolicy: Never
          nodeSelector:
            ktis-node: "true"
          volumes:
          - hostPath:
              path: /usr/share/zoneinfo/Asia/Seoul
            name: timezone-config
```

- schedule: "0 */1 * * *", crontab 패턴으로 스케줄 설정이 가능하다.
- concurrencyPolicy: Forbid, Allow, Forbid, Replace 중 하나 Job의 동시 실행 여부, default Allow
- successfulJobsHistoryLimit: 3,  성공한 Job 보관 개수, default 3
- failedJobsHistoryLimit: 1, 실패한 Job 보관 개수, default 1



# 6. k8s Pods간 통신 제어

향후 프로젝트들은 Namespace에 할당되어 Namespace 간 Pods 통신이 불 가능하다. 타 Namespace의 Pods 통신이 필요한 경우 별도 정책 및 특정 label 설정을 통해 가능하다. 아래는 네트워크 정책 설정 관련된 오브젝트를 설명한다.



## 6.1. NetworkPolicy

NetworkPolicy 오브젝트는 Pods 선택 및 규칙을 정의하기 위해 Label을 활용한다. 기본적으로 Pods 간 통신에는 제약이 존재하지 않는다 (by default).

- Sample 예시

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: test-network-policy
  namespace: default
spec:
  podSelector:
    matchLabels:
      role: db
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - ipBlock:
        cidr: 172.17.0.0/16
        except:
        - 172.17.1.0/24
    - namespaceSelector:
        matchLabels:
          project: myproject
    - podSelector:
        matchLabels:
          role: frontend
    ports:
    - protocol: TCP
      port: 6379
  egress:
  - to:
    - ipBlock:
        cidr: 10.0.0.0/24
    ports:
    - protocol: TCP
      port: 5978
```

1. isolates “role=db” pods in the “default” namespace for both ingress and egress traffic
2. (Ingress rules) allows connections to all pods in the “default” namespace with the label “role=db” on TCP port 6379 from:
   - any pod in the “default” namespace with the label “role=frontend”
   - any pod in a namespace with the label “project=myproject”
   - IP addresses in the ranges 172.17.0.0–172.17.0.255 and 172.17.2.0–172.17.255.255 (ie, all of 172.17.0.0/16 except 172.17.1.0/24)

3. (Egress rules) allows connections from any pod in the “default” namespace with the label “role=db” to CIDR 10.0.0.0/24 on TCP port 5978



## 6.2. Namespace 간 통신 제약 정책 적용하기

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-all
  namespace: herasoo
spec:
  podSelector: {}	# herasoo 네임스페이스 내 모든 Pods 대상
  #podSelector:
    #matchLabels:
      #app: herasoo
  policyTypes:
  - Ingress
  ingress:
  #- {}		# 모든 ingress를 허용
  - from:
    - namespaceSelector:
        matchLabels:
          project: herasoo
```

herasoo 네임스페이스 내 모든 Pods는 "project=herasoo" Label을 가지고 있는 Namespace의 Pods로부터의 호출만을 허용한다.



# 7. k8s Pods의 Node 배치

일반적으로 Pods는 scheduler에 의해 자동적으로 합리적인 위치에 배치하게 된다. Pods의 Node 배치 설정 방법은 아래와 같다.

## 7.1. nodeSelector

PodSpec의 부분이다. 참고로 nodeSelector는 추후 Affinity spec(현, 베타 버전)으로 대체될 예정이다.

- 우선 Node의 Label 정보를 확인하고 설정한다.

```bash
kubectl get nodes --show-labels

#kubectl label nodes <node-name> <label-key>=<label-value>
kubectl label nodes herasoo-worker-node1 disktype=ssd
```

- yaml

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx
  labels:
    env: test
spec:
  containers:
  - name: nginx
    image: nginx
    imagePullPolicy: IfNotPresent
  nodeSelector:
    disktype: ssd
```



## 7.2. nodeName

PodSpec의 부분이다. 그리고 어느 설정보다 우선 시 된다.

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx
  nodeName: herasoo-worker-node1
```



