# 트래픽 제어 가이드



### 사전 준비

- .vimrc

```bash
set smartindent
set tabstop=2
set expandtab
set shiftwidth=2
```

docker, kubernetes, istio환경에서 개발을 하다보면 yaml 파일 작성일 필수적이다. 이에 따라 vi 환경에서 tab 버튼을 통해 smartindent가 되도록 설정한다.



- alias 설정

```bash
alias i='istioctl -n herasoo'
alias k='kubectl -n herasoo'
alias ki='kubectl -n istio-system'
alias oc='oc -n herasoo'
alias oci='oc -n istio-system'
```

kubectl, oc, istioctl 명령 사용 시 namespace에 대한 설정이 필요하다. 이에 위의 예제의 경우 "herasoo" namespace 정보를 alias 설정하여 사용하도록 한다.



### k8s 환경 web-application 서비스

- application jar 파일 준비

```bash
-rwxr--r--.  1 bsscoe bsscoe 19959625 Feb 27 19:37 microSvc1-0.0.1-SNAPSHOT.jar
-rwxr--r--.  1 bsscoe bsscoe 19958600 Feb 27 19:38 microSvc2-0.0.1-SNAPSHOT.jar
```

spring boot를 가지고 작성된 microSvc1, microSvc2 2개의 application을 가지고 설명하며 해당 application은 컨테이너 클러스터 밖의 VM DB와 통신하고 컨테이너 클러스너 안에서 microSvc1<=> microSvc2 간 통신하는 구조이다.



- Dockerfile 작성

Dockerfile-micro-svc-1

```bash
FROM ktis-bastion01.container.ipc.kt.com:5000/admin/openjdk:8-jre-alpine # 베이스이미지
LABEL author=herasoo
COPY microSvc1-0.0.1-SNAPSHOT.jar app.jar
CMD ["java","-jar","app.jar"]
```

Dockerfile-micro-svc-2

```bash
FROM ktis-bastion01.container.ipc.kt.com:5000/admin/openjdk:8-jre-alpine # 베이스이미지
LABEL author=herasoo
COPY microSvc1-0.0.2-SNAPSHOT.jar app.jar
CMD ["java","-jar","app.jar"]
```



자세한 docker command 관련해서 http://gitlab.msa.kt.com/coe-istio-master/msa-bunker/tree/master/knowledge-asset/docker 를 참조하도록 한다.



- 이미지 생성

```bash
docker build --no-cache -t ktis-bastion01.container.ipc.kt.com:5000/herasoo/micro-svc-1:0.1 -f Dockerfile-micro-svc-1 .
docker build --no-cache -t ktis-bastion01.container.ipc.kt.com:5000/herasoo/micro-svc-2:0.1 -f Dockerfile-micro-svc-2 .
```



- 이미지 Docker registry에 push

```bash
docker push ktis-bastion01.container.ipc.kt.com:5000/herasoo/micro-svc-1:0.1
docker push ktis-bastion01.container.ipc.kt.com:5000/herasoo/micro-svc-2:0.1
```



#### ConfigMap

- 100-micro-svc-configmap.yaml

```yml
apiVersion: v1
kind: ConfigMap
metadata:
  name: micro-svc-config
  labels:
    app: micro-svc
    appName: micro-svc	# 프로젝트명, 시스템명, 어플리케이션명
    svcName: micro-svc  # 서비스명
    version: 1.0.0
data:
  SVC1HOST: "service-micro-svc-1.herasoo.svc.cluster.local"
  SVC2HOST: "service-micro-svc-2.herasoo.svc.cluster.local"
  SVC1PORT: "80"
  SVC2PORT: "80"
  DB_HOST: "10.217.59.20"
  DB_PORT: "5432"
  DB_DBNAME: "postgres"
  DB_USER: "postgres"
  DB_PASSWD: "postgres" # passwd와 같은 민감정보는 암호화가 필요하다.
```

spring boot로 작성된 application에서 사용할 환경변수를 필요 시 환경별로 동적으로 관리하기 위함이다.

위의 정보는 spring boot application 내 application.yaml에 아래와 같이 정의 되어 있다.

```yaml
server:
  port: 8080
  servlet:
    context-path: /svc1

spring:
  datasource:
    url: jdbc:postgresql://${DB_HOST:localhost}:${DB_PORT:5432}/${DB_DBNAME:postgres}
    driver-class-name: org.postgresql.Driver
    username: ${DB_USER:postgres}
    password: ${DB_PASSWD:postgres}
    hikari:
      connection-test-query: select 1
      connection-timeout: 5000
      idle-timeout: 30000
  jpa:
    database-platform: org.hibernate.dialect.PostgreSQLDialect
    
herasoo:
  name: wonho
  host:
    svc1: ${SVC1HOST:localhost}
    svc2: ${SVC2HOST:localhost}
  port:
    svc1: ${SVC1PORT:8080}
    svc2: ${SVC2PORT:8090}
debug: false
```



#### Deployment

deployment --> replicaset --> pod를 생성한다.



- 200-micro-svc-1-deployment.yaml

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: deployment-micro-svc-1
  labels:
    appName: micro-svc	# 프로젝트명, 시스템명, 어플리케이션명
    svcName: micro-svc  # 서비스명
    version: 1.0.0
spec:
  selector:
    matchLabels:
      app: micro-svc-1
  replicas: 1
  template:
    metadata:
      labels:
        app: micro-svc-1
      #annotations:
        #sidecar.istio.io/inject: "true"
    spec:
      containers:
      - name: micro-svc-1
        image: ktis-bastion01.container.ipc.kt.com:5000/herasoo/micro-svc-1:0.1
        imagePullPolicy: Always 	# Always, IfNotPresent, Never. dafault IfNotPresent
        ports:
        - containerPort: 8080
        envFrom:
        - configMapRef:
            name: micro-svc-config
      nodeSelector:
        ktis-node: "true"
      restartPolicy: Always		# Always, OnFailure, and Never. default Always
```



- 210-micro-svc-2-deployment.yaml

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: deployment-micro-svc-2
spec:
  selector:
    matchLabels:
      app: micro-svc-2
  replicas: 1
  template:
    metadata:
      labels:
        app: micro-svc-2
      #annotations:
        #sidecar.istio.io/inject: "true"
    spec:
      containers:
      - name: micro-svc-2
        image: ktis-bastion01.container.ipc.kt.com:5000/herasoo/micro-svc-2:0.1
        imagePullPolicy: Always 	# Always, IfNotPresent, Never. dafault IfNotPresent
        ports:
        - containerPort: 8090
        envFrom:
        - configMapRef:
            name: micro-svc-config
      nodeSelector:
        ktis-node: "true"
      restartPolicy: Always		# Always, OnFailure, and Never. default Always
```



#### Service

컨테이너 클러스터 환경에서 Pod의 IP는 시작, 재시작 시 배치되는 Node의 위치에 따라 IP 정보는 변경된다. 그래서 Pod의 동적 부분을 정적으로 서비스하기 위해 Service 객체를 활용하는데 Pod 내부에서 컨테이너 클러스터 환경 내 다른 Pod로 호출 시 Service 객체를 활용하고 그 때 host 정보는 Service 객체의 name이 된다.

동일 Namespace 안에서는 `service-micro-svc-1`와 같이 Service name으로 지칭하고 다른 Namespace의 Service의 경우FQDN 방식의 `service-micro-svc-1.herasoo.svc.cluster.local (서비스명.namespace명.svc.cluster.local)`와 같이 사용한다.



- 300-micro-svc-1-service.yaml

```yaml
apiVersion: v1
kind: Service
metadata:
  name: service-micro-svc-1
  labels:
    app: service-micro-svc-1
    appName: micro-svc	  # 프로젝트명, 시스템명, 어플리케이션명
    svcName: micro-svc-1  # 서비스명
    version: 1.0.0
spec:
  #type: NodePort
  type: ClusterIP
  ports:
  - name: http
    port: 80
    targetPort: 8080
  #clusterIP: None
  selector:
    app: micro-svc-1
```



- 310-micro-svc-2-service.yaml

```yaml
apiVersion: v1
kind: Service
metadata:
  name: service-micro-svc-2
  labels:
    app: service-micro-svc-2
spec:
  #type: NodePort
  type: ClusterIP
  ports:
  - name: http
    port: 80
    targetPort: 8090
  selector:
    app: micro-svc-2
```



#### Route

Route의 경우 openshift Object이기 때문에 oc 명령을 사용해야 한다.

ex) oc apply -f 400-micro-svc-1-route.yaml



- 400-micro-svc-1-route.yaml

```yaml
apiVersion: route.openshift.io/v1
kind: Route
metadata:
  name: route-micro-svc-1
  labels:
    appName: micro-svc	  # 프로젝트명, 시스템명, 어플리케이션명
    svcName: micro-svc    # 서비스명
    version: 1.0.0
spec:
  host: micro-svc.container.ipc.kt.com
  port:
    #targetPort: 80    # to Service 객체의 ports name이 되어야 한다.
    targetPort: http
  path: "/svc1"
  to:
    kind: Service
    name: service-micro-svc-1 # service-micro-svc-1.herasoo.svc.cluster.local 와 같이FQDN 으로 작성하면 에러난다.
    weight: 100
  wildcardPolicy: None
```



- 410-micro-svc-2-route.yaml

```yaml
apiVersion: route.openshift.io/v1
kind: Route
metadata:
  name: route-micro-svc-2
spec:
  host: micro-svc.container.ipc.kt.com
  port:
    #targetPort: 80 # to Service 객체의 ports name이 되어야 한다.
    targetPort: http
  path: "/svc2"
  to:
    kind: Service
    name: service-micro-svc-2 # service-micro-svc-2.herasoo.svc.cluster.local 와 같이FQDN 으로 작성하면 에러난다.
    weight: 100
  wildcardPolicy: None
```



- 로컬 PC에서 접속 확인하기

로컬 hosts 파일에 도메인정보 추가

```bash
10.217.58.25      micro-svc.container.ipc.kt.com 	# DEV환경 DMz Infra Node L4
#10.217.59.30      micro-svc1.container.ipc.kt.com 	# DEV환경 KTIS Infra Node L4
```



http://micro-svc.container.ipc.kt.com/svc1

http://micro-svc.container.ipc.kt.com/svc1/hello

http://micro-svc.container.ipc.kt.com/svc1/testPage1.html (microSvc1 -> DB)

http://micro-svc.container.ipc.kt.com/svc1/testPage2.html (microSvc1 -> DB -> microSvc2 -> DB)



http://micro-svc.container.ipc.kt.com/svc2

http://micro-svc.container.ipc.kt.com/svc2/hello

http://micro-svc.container.ipc.kt.com/svc2/testPage1.html (microSvc2 -> DB)

http://micro-svc.container.ipc.kt.com/svc2/testPage2.html (microSvc2 -> DB -> microSvc1 -> DB)



### k8s 환경 batch-application 서비스

#### Job

job --> pod를 생성한다.

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: job-micro-svc-batch
  labels:
    appName: micro-svc	    # 프로젝트명, 시스템명, 어플리케이션명
    svcName: micro-svc-1    # 서비스명
    version: 1.0.0
spec:
  #ttlSecondsAfterFinished: 50	# Pod가 종료되면 50s 후 지워진다. 0은 바로 지운다. v1.12 이후 제공
  backoffLimit: 2	# 실패 시 재 시작 회수로 +1만큼의 Pod가 생성된다, default는 6
  #completions: 5	# Completed Pods의 개수
  #parallelism: 2   # 1이면 순차처리이고 동시 실행하는 Pods의 개수, default 1
  template:
    metadata:
      name: micro-svc-batch
    spec:
      containers:
        - name: micro-svc-batch
          image: ktis-bastion01.container.ipc.kt.com:5000/busybox:latest
          args:
            - /bin/sh
            - '-c'
            - date; echo Hello from the Kubernetes cluster; return 0;
      restartPolicy: Never    # Never or OnFailure, Never는 새로운 Pod로 기동되고 OnFailure는 기존 Pod가 RESTART된다.
```

Job이 실행되면 정의된 spec에 맞추어 Pods를 실행시키고 Completed, Error상태로 종료된다. 이는 Pod의 프로세스 exit코드(0이면 성공, 그외 실패)에 의해서 관리되는데 실패 시 설정에 따라 재 실행여부를 결정 할 수 있다.



#### CronJob

Cron job은 time-based schedule에 맞추어 Job을 생성한다.

cron job --> job --> pod를 생성한다.

```yaml
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: cronjob-micro-svc-batch
  labels:
    appName: micro-svc	    # 프로젝트명, 시스템명, 어플리케이션명
    svcName: micro-svc-1    # 서비스명
    version: 1.0.0
spec:
  #schedule: '@daily'
  schedule: "*/5 * * * *"
  concurrencyPolicy: Forbid 	# Allow, Forbid, Replace 중 하나 Job의 동시 실행 여부, default Allow
  successfulJobsHistoryLimit: 3 # 성공한 Job 보관 개수, default 3
  failedJobsHistoryLimit: 1		# 실패한 Job 보관 개수, default 1
  jobTemplate:
    spec:
      #ttlSecondsAfterFinished: 50	# Pod가 종료되면 50s 후 지워진다. 0은 바로 지운다. v1.12 이후 제공
  	  backoffLimit: 2	# 실패 시 재 시작 회수로 +1만큼의 Pod가 생성된다, default는 6
  	  #completions: 5	# Completed Pods의 개수
      #parallelism: 2   # 1이면 순차처리이고 동시 실행하는 Pods의 개수, default 1
      template:
        spec:
          containers:
            - name: micro-svc-batch
              image: ktis-bastion01.container.ipc.kt.com:5000/busybox:latest
              args:
                - /bin/sh
                - '-c'
                - date; echo Hello from the Kubernetes cluster; return 0;
          restartPolicy: Never
```



### k8s Pods간 통신 제어

#### NetworkPolicy

NetworkPolicy 오브젝트는 Pods 선택 및 규칙을 정의하기 위해 Label을 활용한다. 기본적으로 Pods 간 통신에는 제약이 존재하지 않는다(by default).

- Sample 예시

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: test-network-policy
  namespace: default
spec:
  podSelector:
    matchLabels:
      role: db
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - ipBlock:
        cidr: 172.17.0.0/16
        except:
        - 172.17.1.0/24
    - namespaceSelector:
        matchLabels:
          project: myproject
    - podSelector:
        matchLabels:
          role: frontend
    ports:
    - protocol: TCP
      port: 6379
  egress:
  - to:
    - ipBlock:
        cidr: 10.0.0.0/24
    ports:
    - protocol: TCP
      port: 5978
```

1. isolates “role=db” pods in the “default” namespace for both ingress and egress traffic
2. (Ingress rules) allows connections to all pods in the “default” namespace with the label “role=db” on TCP port 6379 from:
   - any pod in the “default” namespace with the label “role=frontend”
   - any pod in a namespace with the label “project=myproject”
   - IP addresses in the ranges 172.17.0.0–172.17.0.255 and 172.17.2.0–172.17.255.255 (ie, all of 172.17.0.0/16 except 172.17.1.0/24)

3. (Egress rules) allows connections from any pod in the “default” namespace with the label “role=db” to CIDR 10.0.0.0/24 on TCP port 5978



- Namespace 간 통신 제약 정책 적용하기

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-all
  namespace: herasoo
spec:
  podSelector: {}	# herasoo 네임스페이스 내 모든 Pods 대상
  #podSelector:
    #matchLabels:
      #app: herasoo
  policyTypes:
  - Ingress
  ingress:
  #- {}		# 모든 ingress를 허용
  - from:
    - namespaceSelector:
        matchLabels:
          project: herasoo
```

herasoo 네임스페이스 내 모든 Pods는 "project=herasoo" Label을 가지고 있는 Namespace의 Pods로부터의 호출만을 허용한다.



### k8s Pods의 Node 배치

일반적으로 Pods는 scheduler에 의해 자동적으로 합리적인 위치에 배치하게 된다. Pods의 Node 배치 설정 방법은 아래와 같다.

#### nodeSelector

PodSpec의 부분이다. 참고로 nodeSelector는 추후 Affinity spec(현, 베타 버전)으로 대체될 예정이다.

- 우선 Node의 Label 정보를 확인하고 설정한다.

```bash
kubectl get nodes --show-labels

#kubectl label nodes <node-name> <label-key>=<label-value>
kubectl label nodes herasoo-worker-node1 disktype=ssd
```

- yaml

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx
  labels:
    env: test
spec:
  containers:
  - name: nginx
    image: nginx
    imagePullPolicy: IfNotPresent
  nodeSelector:
    disktype: ssd
```



#### nodeName

PodSpec의 부분이다. 그리고 어느 설정보다 우선 시 된다.

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx
  nodeName: herasoo-worker-node1
```



